{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJupxKUlq/5qqBjsPlKKLq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaYunJeong/K-Digital-Training-Class/blob/main/Aug06_4_Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 표제어 추출 (Lemmatization)\n",
        "\n",
        "말뭉치(코퍼스)의 단어의 갯수를 줄일 수 있는 기법\n",
        "\n",
        "be 동사 : be, am, are, is\n",
        "\n",
        "공부하다 : 공부하고, 공부때문에, 공부여서, 공부덕분에, ...(여러 조사 붙여서 표현)\n",
        "\n",
        "- 분석시에 단어 빈도수 기반으로 진행 => 자연어 처리 단계에서 상당히 자주 사용\n",
        "\n",
        "- 형태소로부터 단어를 만들어가는...\n",
        "  - 어간(stem) : 의미가 있는 단어의 핵심부분 (공부)\n",
        "  - 접사(affix) : 단어에 추가적인 의미를 부여하는 부분 (하고, 때문에...)\n",
        "\n",
        "  형태학적 파싱 : 코퍼스에서 어간과 접사를 분리하는 것\n",
        "\n",
        "ex ) students => student + s"
      ],
      "metadata": {
        "id": "0Abo1lOqGiAs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0qP2WTrGaz-",
        "outputId": "63e2d9e4-354d-4daa-b069-132c382425d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WordNetLemmatizer : NLTK에서 지원하는 표제어 추출 도구\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPWRmia_H8q9",
        "outputId": "ebf1e128-4b20-4ff5-afa2-9263c21f09d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = ['sky', 'computer', 'having', 'lives', 'love', 'mouse', 'dies', 'listened', 'ate', 'has']\n",
        "print('추출 전 : ', words)\n",
        "print('추출 후 : ', [lemmatizer.lemmatize(word) for word in words])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjcOPxwPIJt8",
        "outputId": "7a0e4bbf-7c5a-45c3-ba63-1989d56d278b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "추출 전 :  ['sky', 'computer', 'having', 'lives', 'love', 'mouse', 'dies', 'listened', 'ate', 'has']\n",
            "추출 후 :  ['sky', 'computer', 'having', 'life', 'love', 'mouse', 'dy', 'listened', 'ate', 'ha']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('dies', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2yaDkOD2Im8j",
        "outputId": "d0478820-eea9-4d94-98af-b4ac58cd1fe1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'die'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('listened', 'v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CUn_Bi87JTBT",
        "outputId": "e898bf53-fb29-4ab0-af87-54c6f714a961"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'listen'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize('better', 'a')\n",
        "\n",
        "# v : 동사 / a : 형용사 / n : 명사 / r : 부사"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aD9-XKc5JW4D",
        "outputId": "572a5cc8-df35-4c34-ba0f-3e41b1cc11a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'good'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 어간 추출 (Stemming)"
      ],
      "metadata": {
        "id": "ONCsUb1DJwNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4YyaxYHJg2L",
        "outputId": "c5b6cdda-12f0-4304-d270-b60b62b41426"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "E70WEtWyJ8AL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"It was on seeing that boy that I understood, for the first time, my situation. I had thought up to that moment of the adventures before me, not at all of the home that I was leaving; and now, at sight of this clumsy stranger, who was to stay here in my place beside my mother, I had my first attack of tears. I am afraid I led that boy a dog’s life, for as he was new to the work, I had a hundred opportunities of setting him right and putting him down, and I was not slow to profit by them.\"\"\""
      ],
      "metadata": {
        "id": "e6PZXTnEKFBD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "words2 = word_tokenize(sentence)\n",
        "print(words2)\n",
        "print([stemmer.stem(w) for w in words2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM2j7J5ZKPWs",
        "outputId": "1da076b5-20e3-4884-e57f-34505f05c344"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'was', 'on', 'seeing', 'that', 'boy', 'that', 'I', 'understood', ',', 'for', 'the', 'first', 'time', ',', 'my', 'situation', '.', 'I', 'had', 'thought', 'up', 'to', 'that', 'moment', 'of', 'the', 'adventures', 'before', 'me', ',', 'not', 'at', 'all', 'of', 'the', 'home', 'that', 'I', 'was', 'leaving', ';', 'and', 'now', ',', 'at', 'sight', 'of', 'this', 'clumsy', 'stranger', ',', 'who', 'was', 'to', 'stay', 'here', 'in', 'my', 'place', 'beside', 'my', 'mother', ',', 'I', 'had', 'my', 'first', 'attack', 'of', 'tears', '.', 'I', 'am', 'afraid', 'I', 'led', 'that', 'boy', 'a', 'dog', '’', 's', 'life', ',', 'for', 'as', 'he', 'was', 'new', 'to', 'the', 'work', ',', 'I', 'had', 'a', 'hundred', 'opportunities', 'of', 'setting', 'him', 'right', 'and', 'putting', 'him', 'down', ',', 'and', 'I', 'was', 'not', 'slow', 'to', 'profit', 'by', 'them', '.']\n",
            "['it', 'wa', 'on', 'see', 'that', 'boy', 'that', 'i', 'understood', ',', 'for', 'the', 'first', 'time', ',', 'my', 'situat', '.', 'i', 'had', 'thought', 'up', 'to', 'that', 'moment', 'of', 'the', 'adventur', 'befor', 'me', ',', 'not', 'at', 'all', 'of', 'the', 'home', 'that', 'i', 'wa', 'leav', ';', 'and', 'now', ',', 'at', 'sight', 'of', 'thi', 'clumsi', 'stranger', ',', 'who', 'wa', 'to', 'stay', 'here', 'in', 'my', 'place', 'besid', 'my', 'mother', ',', 'i', 'had', 'my', 'first', 'attack', 'of', 'tear', '.', 'i', 'am', 'afraid', 'i', 'led', 'that', 'boy', 'a', 'dog', '’', 's', 'life', ',', 'for', 'as', 'he', 'wa', 'new', 'to', 'the', 'work', ',', 'i', 'had', 'a', 'hundr', 'opportun', 'of', 'set', 'him', 'right', 'and', 'put', 'him', 'down', ',', 'and', 'i', 'wa', 'not', 'slow', 'to', 'profit', 'by', 'them', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PorterStemmer : 알고리즘\n",
        "\n",
        "규칙 기반의 접근 => 어림짐작하는 작업 => 섬세한 작업 X => 사전에 없는 단어가 도출될수도...!\n",
        "\n",
        "- 마틴포터 홈페이지에서 다양한 것들을 살펴볼 수 있음\n",
        "- 규칙 기반의 접근\n",
        "  - -ALIZE = -AL\n",
        "  - -ANCE => 삭제\n",
        "  - -ICAL => -IC\n"
      ],
      "metadata": {
        "id": "J3zaZoj1Kx4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = ['channelize', 'allowance', 'typical']\n",
        "\n",
        "print('추출 전 : ', word)\n",
        "print('추출 후 : ', [stemmer.stem(w) for w in word])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_cBrnH1KmgE",
        "outputId": "496700c7-9adc-46c7-b0e3-701d75b363ca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "추출 전 :  ['channelize', 'allowance', 'typical']\n",
            "추출 후 :  ['channel', 'allow', 'typic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK에서는 포터 알고리즘 외에도 랭커스터 스태머(Lancaster Stemmer) 알고리즘을 지원\n",
        "from nltk.stem import LancasterStemmer"
      ],
      "metadata": {
        "id": "xv2DCxQILpec"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lancaster = LancasterStemmer()"
      ],
      "metadata": {
        "id": "Y3lW6h8JL64k"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([stemmer.stem(w) for w in words])\n",
        "print()\n",
        "print([lancaster.stem(w) for w in words])\n",
        "\n",
        "# 두 스태머가 다른 결과를 보여줌\n",
        "# 두 스태머는 서로 다른 알고리즘을 사용하기 때문!\n",
        "# 제대로 된 표제어를 뽑아오지 못하고 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5IrL58WL9l0",
        "outputId": "e37ed1ee-c1a1-4092-f519-fd7fed3bb1a0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sky', 'comput', 'have', 'live', 'love', 'mous', 'die', 'listen', 'ate', 'ha']\n",
            "\n",
            "['sky', 'comput', 'hav', 'liv', 'lov', 'mous', 'die', 'list', 'at', 'has']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 불용어 (Stopword)\n",
        "\n",
        "단어들 중에서 의미가 없는 단어\n",
        "\n",
        "데이터 중에서 의미가 있는 단어 토큰만 취급하기 위해서 의미를 가지지 않은 단어들을 제거하는 작업"
      ],
      "metadata": {
        "id": "AOh7cojcMo-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67Zf3fGyMHb0",
        "outputId": "6dfaceda-8a5f-4efd-f6a3-7f5f9450b0e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "CO4PW73gNOjt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK에 있는 불용어\n",
        "s = stopwords.words('english')\n",
        "print(len(s))\n",
        "print(s[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMYU3aamNSK8",
        "outputId": "b2c89653-936a-41d5-baa9-c98d900b4152"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"It was on seeing that boy that I understood, for the first time, my situation. I had thought up to that moment of the adventures before me, not at all of the home that I was leaving; and now, at sight of this clumsy stranger, who was to stay here in my place beside my mother, I had my first attack of tears. I am afraid I led that boy a dog’s life, for as he was new to the work, I had a hundred opportunities of setting him right and putting him down, and I was not slow to profit by them.\"\"\"\n",
        "\n",
        "# NLTK에서 지정한 불용어 가져오기\n",
        "sw = set(stopwords.words('english'))\n",
        "# print(sw)\n",
        "\n",
        "# 문장을 단어로 쪼개는 작업\n",
        "word = word_tokenize(sentence)\n",
        "\n",
        "# 불용어가 아닌 단어들만 list에 담아서 출력\n",
        "result = []\n",
        "for w in word:\n",
        "  if w not in sw:\n",
        "    result.append(w)\n",
        "\n",
        "print(word)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CZnPdgENdS8",
        "outputId": "38f94800-5a44-4a3b-8dea-00d27856df43"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['It', 'was', 'on', 'seeing', 'that', 'boy', 'that', 'I', 'understood', ',', 'for', 'the', 'first', 'time', ',', 'my', 'situation', '.', 'I', 'had', 'thought', 'up', 'to', 'that', 'moment', 'of', 'the', 'adventures', 'before', 'me', ',', 'not', 'at', 'all', 'of', 'the', 'home', 'that', 'I', 'was', 'leaving', ';', 'and', 'now', ',', 'at', 'sight', 'of', 'this', 'clumsy', 'stranger', ',', 'who', 'was', 'to', 'stay', 'here', 'in', 'my', 'place', 'beside', 'my', 'mother', ',', 'I', 'had', 'my', 'first', 'attack', 'of', 'tears', '.', 'I', 'am', 'afraid', 'I', 'led', 'that', 'boy', 'a', 'dog', '’', 's', 'life', ',', 'for', 'as', 'he', 'was', 'new', 'to', 'the', 'work', ',', 'I', 'had', 'a', 'hundred', 'opportunities', 'of', 'setting', 'him', 'right', 'and', 'putting', 'him', 'down', ',', 'and', 'I', 'was', 'not', 'slow', 'to', 'profit', 'by', 'them', '.']\n",
            "['It', 'seeing', 'boy', 'I', 'understood', ',', 'first', 'time', ',', 'situation', '.', 'I', 'thought', 'moment', 'adventures', ',', 'home', 'I', 'leaving', ';', ',', 'sight', 'clumsy', 'stranger', ',', 'stay', 'place', 'beside', 'mother', ',', 'I', 'first', 'attack', 'tears', '.', 'I', 'afraid', 'I', 'led', 'boy', 'dog', '’', 'life', ',', 'new', 'work', ',', 'I', 'hundred', 'opportunities', 'setting', 'right', 'putting', ',', 'I', 'slow', 'profit', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 한국어 불용어 제거하기\n",
        "\n",
        "- 토큰화 => 조사 or 접속사 같이 명사 or 형용사에서 필요없는 단어들을 제거\n",
        "\n",
        "- 한국어의 경우에는 사용자가 직접 불용어를 지정해서 사용하는 경우가 많음"
      ],
      "metadata": {
        "id": "iCTXm4wmRvxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHkLZRHINoTK",
        "outputId": "ad50ea89-878f-4f5a-b1f7-e3504b73d9ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from Konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from Konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from Konlpy) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->Konlpy) (24.1)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, Konlpy\n",
            "Successfully installed JPype1-1.5.0 Konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt"
      ],
      "metadata": {
        "id": "jaNPgeW8SP9W"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "okt = Okt()\n",
        "\n",
        "ex = \"점심 먹고 나서 피곤하시죠? 여러분은 어떤 메뉴를 드셨나요? 저는 초밥을 먹었습니다.\"\n",
        "sw = \"를 어떤 는 은 을\"\n",
        "\n",
        "sw = set(sw.split(' '))\n",
        "token = okt.morphs(ex)  # 형태소 분석\n",
        "\n",
        "result = [w for w in token if w not in sw]\n",
        "\n",
        "print(token)  # 불용어 제거 전\n",
        "print()\n",
        "print(result) # 불용어 제거 후"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_ITubixST_-",
        "outputId": "53cf2a71-97a0-422d-dcf3-77c7622d6828"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['점심', '먹고', '나서', '피곤하시죠', '?', '여러분', '은', '어떤', '메뉴', '를', '드셨나요', '?', '저', '는', '초밥', '을', '먹었습니다', '.']\n",
            "\n",
            "['점심', '먹고', '나서', '피곤하시죠', '?', '여러분', '메뉴', '드셨나요', '?', '저', '초밥', '먹었습니다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정수 인코딩 (Integer Encoding)\n",
        "\n",
        "컴퓨터의 입장에서는 텍스트보다는 숫자를 더 쉽게 처리하는 경향이 있음\n",
        "\n",
        "텍스트에 정수를 부여하는 방법\n",
        "1. 단어를 빈도수를 기준으로 정렬\n",
        "2. 정렬된 집합 구성\n",
        "3. 빈도가 높은순 => 낮은순으로 숫자를 부여"
      ],
      "metadata": {
        "id": "YfFY8a56S422"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 동요\n",
        "text = \"\"\"Twinkle, twinkle, little star.\n",
        "How I wonder what you are.\n",
        "Up above the world so high.\n",
        "Like a diamond in the sky.\n",
        "Twinkle, twinkle little star.\n",
        "How I wonder what you are.\n",
        "When the blazing sun is gone.\n",
        "When he nothing shines upon.\n",
        "Then you show your little light.\n",
        "Twinkle, twinkle, all the night.\n",
        "Twinkle, twinkle, little star.\n",
        "How I wonder what you are.\n",
        "Twinkle, twinkle, little star.\n",
        "How I wonder what you are.\n",
        "Up above the world so high.\n",
        "Like a diamond in the sky.\n",
        "Twinkle, twinkle little star.\n",
        "How I wonder what you are.\n",
        "When the blazing sun is gone.\n",
        "When he nothing shines upon.\n",
        "Then you show your little light.\n",
        "Twinkle, twinkle, all the night.\n",
        "Twinkle, twinkle, little star.\n",
        "How I wonder what you are.\"\"\"\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "UNopl3YQS3ww",
        "outputId": "4f6f6dff-d1aa-475f-a3fc-e506f3e66371"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Twinkle, twinkle, little star.\\nHow I wonder what you are.\\nUp above the world so high.\\nLike a diamond in the sky.\\nTwinkle, twinkle little star.\\nHow I wonder what you are.\\nWhen the blazing sun is gone.\\nWhen he nothing shines upon.\\nThen you show your little light.\\nTwinkle, twinkle, all the night.\\nTwinkle, twinkle, little star.\\nHow I wonder what you are.\\nTwinkle, twinkle, little star.\\nHow I wonder what you are.\\nUp above the world so high.\\nLike a diamond in the sky.\\nTwinkle, twinkle little star.\\nHow I wonder what you are.\\nWhen the blazing sun is gone.\\nWhen he nothing shines upon.\\nThen you show your little light.\\nTwinkle, twinkle, all the night.\\nTwinkle, twinkle, little star.\\nHow I wonder what you are.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize   # 영어 문장 토큰화\n",
        "from nltk.tokenize import word_tokenize   # 영어 단어 토큰화\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "UyxFpd4cUVjW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 토큰화\n",
        "sentence = sent_tokenize(text)\n",
        "sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKJKbvyFUw7u",
        "outputId": "72f137da-5dc3-439f-e990-6e075f3b970e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Twinkle, twinkle, little star.',\n",
              " 'How I wonder what you are.',\n",
              " 'Up above the world so high.',\n",
              " 'Like a diamond in the sky.',\n",
              " 'Twinkle, twinkle little star.',\n",
              " 'How I wonder what you are.',\n",
              " 'When the blazing sun is gone.',\n",
              " 'When he nothing shines upon.',\n",
              " 'Then you show your little light.',\n",
              " 'Twinkle, twinkle, all the night.',\n",
              " 'Twinkle, twinkle, little star.',\n",
              " 'How I wonder what you are.',\n",
              " 'Twinkle, twinkle, little star.',\n",
              " 'How I wonder what you are.',\n",
              " 'Up above the world so high.',\n",
              " 'Like a diamond in the sky.',\n",
              " 'Twinkle, twinkle little star.',\n",
              " 'How I wonder what you are.',\n",
              " 'When the blazing sun is gone.',\n",
              " 'When he nothing shines upon.',\n",
              " 'Then you show your little light.',\n",
              " 'Twinkle, twinkle, all the night.',\n",
              " 'Twinkle, twinkle, little star.',\n",
              " 'How I wonder what you are.']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 토큰화 => 불용어를 뺀 단어 토큰들을 list에 담기\n",
        "\n",
        "sw = set(stopwords.words('english'))\n",
        "final_sentence = []\n",
        "aa = {}\n",
        "\n",
        "for s in sentence:\n",
        "  # 단어 토큰화\n",
        "  word = word_tokenize(s)\n",
        "  result = []\n",
        "  for w in word:\n",
        "    w = w.lower() # 모든 단어를 소문자화 => 단어 갯수를 줄이는데 도움 O\n",
        "    if w not in sw:\n",
        "      if len(w) > 2:\n",
        "        result.append(w)\n",
        "        if w not in aa:\n",
        "          aa[w] = 0\n",
        "        aa[w] += 1\n",
        "  final_sentence.append(result)\n",
        "print(final_sentence)\n",
        "print(aa)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRsvhCxjU3Ju",
        "outputId": "071414be-8ce2-430a-9486-226a3c431d13"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['twinkle', 'twinkle', 'little', 'star'], ['wonder'], ['world', 'high'], ['like', 'diamond', 'sky'], ['twinkle', 'twinkle', 'little', 'star'], ['wonder'], ['blazing', 'sun', 'gone'], ['nothing', 'shines', 'upon'], ['show', 'little', 'light'], ['twinkle', 'twinkle', 'night'], ['twinkle', 'twinkle', 'little', 'star'], ['wonder'], ['twinkle', 'twinkle', 'little', 'star'], ['wonder'], ['world', 'high'], ['like', 'diamond', 'sky'], ['twinkle', 'twinkle', 'little', 'star'], ['wonder'], ['blazing', 'sun', 'gone'], ['nothing', 'shines', 'upon'], ['show', 'little', 'light'], ['twinkle', 'twinkle', 'night'], ['twinkle', 'twinkle', 'little', 'star'], ['wonder']]\n",
            "{'twinkle': 16, 'little': 8, 'star': 6, 'wonder': 6, 'world': 2, 'high': 2, 'like': 2, 'diamond': 2, 'sky': 2, 'blazing': 2, 'sun': 2, 'gone': 2, 'nothing': 2, 'shines': 2, 'upon': 2, 'show': 2, 'light': 2, 'night': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'little' 단어의 빈도수\n",
        "print(aa['little'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m34hBw5hV8nP",
        "outputId": "3dc3cfed-1e56-440c-ebce-ea2c32f9206f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sorted() 함수 : 빈도수대로 정렬\n",
        "# sorted(정렬할 데이터, key옵션, reverse옵션)\n",
        "#   key 옵션 : 어떤것을 기준으로 정렬할지 (key에 준 값으로 정렬)\n",
        "#   reverse옵션 : False(default) >> 오름차순\n",
        "\n",
        "# sort() vs sorted() :\n",
        "#   sort()는 리스트 자체를 정렬해서 바꾸는 형태\n",
        "#   sorted()는 원래 리스트는 그대로 두고, 정렬한 것을 새로운 리스트에 넣는 형태\n",
        "\n",
        "# key = lambda x: x[1] => x[1]의 값이 정렬의 기준 => 빈도수를 기준으로 정렬\n",
        "\n",
        "aaSort = sorted(aa.items(), key=lambda x: x[1], reverse=True)\n",
        "print(aaSort)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9rOc-nPWQx-",
        "outputId": "046bbb33-0e27-4158-e43b-73edc70042e2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('twinkle', 16), ('little', 8), ('star', 6), ('wonder', 6), ('world', 2), ('high', 2), ('like', 2), ('diamond', 2), ('sky', 2), ('blazing', 2), ('sun', 2), ('gone', 2), ('nothing', 2), ('shines', 2), ('upon', 2), ('show', 2), ('light', 2), ('night', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [높은 빈도수]를 가지고 있는 단어일수록 [낮은 정수값]을 부여 (정수는 1부터 부여)\n",
        "\n",
        "# 빈도수가 1이하인것들은 삭제 (결과에 안나오게)\n",
        "# {'twinkle' : 1, 'little' : 2, 'star' : 3, ...}\n",
        "\n",
        "aa_index = {}\n",
        "i = 0\n",
        "for (word, frequency) in aaSort:\n",
        "  if frequency > 1:\n",
        "    i = i + 1\n",
        "    aa_index[word] = i\n",
        "\n",
        "print(aa_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oJj8LAfXP-n",
        "outputId": "d79089a5-1af5-4b99-9100-f3dab40c47e5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'twinkle': 1, 'little': 2, 'star': 3, 'wonder': 4, 'world': 5, 'high': 6, 'like': 7, 'diamond': 8, 'sky': 9, 'blazing': 10, 'sun': 11, 'gone': 12, 'nothing': 13, 'shines': 14, 'upon': 15, 'show': 16, 'light': 17, 'night': 18}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 단어 빈도수가 가장 높은 상위 5개 출력\n",
        "freSize = 5\n",
        "\n",
        "# 인덱스가 5초과(6이상)인 단어들을 aa_final이라는 변수에 담기\n",
        "aa_final = [w for (w, index) in aa_index.items() if index >= freSize + 1]\n",
        "\n",
        "for w in aa_final:\n",
        "  del aa_index[w]\n",
        "\n",
        "print(aa_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Bm68dqYTlf",
        "outputId": "6b1e4076-14fe-4d10-b9c0-36f795cefaf2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'twinkle': 1, 'little': 2, 'star': 3, 'wonder': 4, 'world': 5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ['twinkle', 'little', 'star', 'wonder', 'coffee']\n",
        "#   >> aa_index에 더이상 존재하지 않는 단어 추가\n",
        "# [1, 2, 3, 4, 5, ??]\n",
        "# Out-Of-Vocabulary : 단어 집합에 없는 단어 >> OOV\n",
        "# aa_index에 'OOV'라는 단어가 있는 자리를 하나 만들고, 그 단어집합에 존재하지 않는 단어를 OOV의 인덱스로 인코딩"
      ],
      "metadata": {
        "id": "3sD5TiM2ZANf"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aa_index['OOV'] = len(aa_index) + 1\n",
        "print(aa_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Al8qaGaG4_",
        "outputId": "1073523a-a31a-4dda-933c-c4591df4311f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'twinkle': 1, 'little': 2, 'star': 3, 'wonder': 4, 'world': 5, 'OOV': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장마다 텍스트 대신에 그 자리에 해당하는 인덱스로 변환\n",
        "# 문장마다 단어로 토큰화 : final_sentence\n",
        "\n",
        "encoding_sentences = []\n",
        "for fs in final_sentence:\n",
        "  encoding_sentence = []\n",
        "  for w in fs:\n",
        "    try:\n",
        "      # 단어 집합에 있는 단어면 해당 단어의 정수를 넣어줌\n",
        "      encoding_sentence.append(aa_index[w])\n",
        "    except KeyError:\n",
        "      # 단어 집합에 없는 단어면 OOV의 정수를 넣어줌\n",
        "      encoding_sentence.append(aa_index['OOV'])\n",
        "  encoding_sentences.append(encoding_sentence)\n",
        "print(encoding_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0OEcTR2aVEE",
        "outputId": "67851514-77e1-48ed-e28a-77b2d735acd3"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 1, 2, 3], [4], [5, 6], [6, 6, 6], [1, 1, 2, 3], [4], [6, 6, 6], [6, 6, 6], [6, 2, 6], [1, 1, 6], [1, 1, 2, 3], [4], [1, 1, 2, 3], [4], [5, 6], [6, 6, 6], [1, 1, 2, 3], [4], [6, 6, 6], [6, 6, 6], [6, 2, 6], [1, 1, 6], [1, 1, 2, 3], [4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "42RLWLWGbbSQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}